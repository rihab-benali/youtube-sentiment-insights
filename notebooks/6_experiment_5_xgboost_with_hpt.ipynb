{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Improving Baseline Model - Hyperparameter tuning with Multiple Improving Baseline"
      ],
      "metadata": {
        "id": "oRbSrr_ZsvSF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4aFNKOE0Ao9i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d23a89-b152-4a29-daa8-bdd3463b9e79"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow==2.7.1 in /usr/local/lib/python3.12/dist-packages (2.7.1)\n",
            "Requirement already satisfied: databricks-cli in /usr/local/lib/python3.12/dist-packages (0.18.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.12/dist-packages (1.42.16)\n",
            "Requirement already satisfied: awscli in /usr/local/lib/python3.12/dist-packages (1.44.6)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (8.3.1)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (2.10.1)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (3.3.1)\n",
            "Requirement already satisfied: requests>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (2.32.4)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (1.17.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.12/dist-packages (from databricks-cli) (2.5.0)\n",
            "Requirement already satisfied: botocore<1.43.0,>=1.42.16 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.42.16)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from boto3) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.17.0,>=0.16.0 in /usr/local/lib/python3.12/dist-packages (from boto3) (0.16.0)\n",
            "Requirement already satisfied: docutils<=0.19,>=0.18.1 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.19)\n",
            "Requirement already satisfied: PyYAML<6.1,>=3.10 in /usr/local/lib/python3.12/dist-packages (from awscli) (6.0.3)\n",
            "Requirement already satisfied: colorama<0.4.7,>=0.2.5 in /usr/local/lib/python3.12/dist-packages (from awscli) (0.4.6)\n",
            "Requirement already satisfied: rsa<4.8,>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from awscli) (4.7.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.12/dist-packages (from botocore<1.43.0,>=1.42.16->boto3) (2.9.0.post0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.17.3->databricks-cli) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.17.3->databricks-cli) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.17.3->databricks-cli) (2025.11.12)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.12/dist-packages (from rsa<4.8,>=3.1.2->awscli) (0.6.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.6.0)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.12/dist-packages (3.1.2)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.12/dist-packages (0.14.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.17.2)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.45)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.3)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.12/dist-packages (from xgboost) (2.28.9)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from xgboost) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: joblib<2,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from imbalanced-learn) (3.6.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.12/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.3)\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# MLflow client (pinned version)\n",
        "# ==============================\n",
        "!pip install mlflow==2.7.1 --no-deps\n",
        "\n",
        "# ==============================\n",
        "# Required MLflow dependencies (minimal)\n",
        "# ==============================\n",
        "!pip install databricks-cli boto3 awscli\n",
        "\n",
        "# ==============================\n",
        "# ML / Optimization libraries\n",
        "# ==============================\n",
        "!pip install optuna xgboost imbalanced-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!aws configure"
      ],
      "metadata": {
        "id": "BRlDAvQBAvMi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ada442-972c-453a-c595-1519aaa2e9c2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AWS Access Key ID [None]: AKIA4KZW6R4DN7FVG2FY\n",
            "AWS Secret Access Key [None]: 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\n",
            "Default region name [None]: eu-north-1\n",
            "Default output format [None]: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mlflow\n",
        "# Step 2: Set up the MLflow tracking server\n",
        "mlflow.set_tracking_uri(\"http://ec2-13-60-99-223.eu-north-1.compute.amazonaws.com:5000/\")"
      ],
      "metadata": {
        "id": "m4GbjyLGAvRp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c97d0d2c-b938-44c9-a321-52373692c052"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/mlflow/protos/service_pb2.py:11: UserWarning: google.protobuf.service module is deprecated. RPC implementations should provide code generator plugins which generate code specific to the RPC implementation. service.py will be removed in Jan 2025\n",
            "  from google.protobuf import service as _service\n",
            "/usr/local/lib/python3.12/dist-packages/pydantic/_internal/_config.py:383: UserWarning: Valid config keys have changed in V2:\n",
            "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
            "  warnings.warn(message, UserWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set or create an experiment\n",
        "mlflow.set_experiment(\"Exp 5 - ML Algos with HP Tuning\")"
      ],
      "metadata": {
        "id": "IqFYRQVeAvWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b4493cc-da34-4a03-c8a7-08cf1fb8262d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025/12/24 00:20:53 INFO mlflow.tracking.fluent: Experiment with name 'Exp 5 - ML Algos with HP Tuning' does not exist. Creating a new experiment.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Experiment: artifact_location='s3://mlflow-mlops-bucket/5', creation_time=1766535653366, experiment_id='5', last_update_time=1766535653366, lifecycle_stage='active', name='Exp 5 - ML Algos with HP Tuning', tags={}>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "uW74niJZA5Ui"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/reddit_preprocessing.csv').dropna()\n",
        "df.shape"
      ],
      "metadata": {
        "id": "O5KQuT0wA7Ma",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8257f45-4f77-4730-92b8-8cb4b54503b1"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(36662, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Remap the class labels from [-1, 0, 1] to [2, 0, 1]\n",
        "df['category'] = df['category'].map({-1: 2, 0: 0, 1: 1})\n",
        "\n",
        "# Step 2: Remove rows where the target labels (category) are NaN\n",
        "df = df.dropna(subset=['category'])\n",
        "\n",
        "ngram_range = (1, 3)  # Trigram setting\n",
        "max_features = 10000  # Set max_features to 1000 for TF-IDF\n",
        "\n",
        "# Step 4: Train-test split before vectorization and resampling\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category'])\n",
        "\n",
        "# Step 2: Vectorization using TF-IDF, fit on training data only\n",
        "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
        "X_train_vec = vectorizer.fit_transform(X_train)  # Fit on training data\n",
        "X_test_vec = vectorizer.transform(X_test)  # Transform test data\n",
        "\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_vec, y_train = smote.fit_resample(X_train_vec, y_train)\n",
        "\n",
        "# Function to log results in MLflow\n",
        "def log_mlflow(model_name, model, X_train, X_test, y_train, y_test):\n",
        "    with mlflow.start_run():\n",
        "        # Log model type\n",
        "        mlflow.set_tag(\"mlflow.runName\", f\"{model_name}_SMOTE_TFIDF_Trigrams\")\n",
        "        mlflow.set_tag(\"experiment_type\", \"algorithm_comparison\")\n",
        "\n",
        "        # Log algorithm name as a parameter\n",
        "        mlflow.log_param(\"algo_name\", model_name)\n",
        "\n",
        "        # Train model\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Log accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        mlflow.log_metric(\"accuracy\", accuracy)\n",
        "\n",
        "        # Log classification report\n",
        "        classification_rep = classification_report(y_test, y_pred, output_dict=True)\n",
        "        for label, metrics in classification_rep.items():\n",
        "            if isinstance(metrics, dict):\n",
        "                for metric, value in metrics.items():\n",
        "                    mlflow.log_metric(f\"{label}_{metric}\", value)\n",
        "\n",
        "        # Log the model\n",
        "        mlflow.sklearn.log_model(model, f\"{model_name}_model\")\n",
        "\n",
        "\n",
        "# Step 6: Optuna objective function for XGBoost\n",
        "def objective_xgboost(trial):\n",
        "    n_estimators = trial.suggest_int('n_estimators', 50, 300)\n",
        "    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-1, log=True)\n",
        "    max_depth = trial.suggest_int('max_depth', 3, 10)\n",
        "\n",
        "    model = XGBClassifier(n_estimators=n_estimators, learning_rate=learning_rate, max_depth=max_depth, random_state=42)\n",
        "    return accuracy_score(y_test, model.fit(X_train_vec, y_train).predict(X_test_vec))\n",
        "\n",
        "\n",
        "# Step 7: Run Optuna for XGBoost, log the best model only\n",
        "def run_optuna_experiment():\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgboost, n_trials=30)\n",
        "\n",
        "    # Get the best parameters and log only the best model\n",
        "    best_params = study.best_params\n",
        "    best_model = XGBClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], max_depth=best_params['max_depth'], random_state=42)\n",
        "\n",
        "    # Log the best model with MLflow, passing the algo_name as \"xgboost\"\n",
        "    log_mlflow(\"XGBoost\", best_model, X_train_vec, X_test_vec, y_train, y_test)\n",
        "\n",
        "# Run the experiment for XGBoost\n",
        "run_optuna_experiment()"
      ],
      "metadata": {
        "id": "2l0kgNWEA-7h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a6cdb44-0946-4475-d26a-7a5977eaa58b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-12-24 00:22:02,296] A new study created in memory with name: no-name-627a528e-7468-4837-b03e-61a239c6475e\n",
            "[I 2025-12-24 00:27:53,683] Trial 0 finished with value: 0.7564434747033956 and parameters: {'n_estimators': 207, 'learning_rate': 0.05732636600851718, 'max_depth': 7}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 00:35:01,433] Trial 1 finished with value: 0.6564843856538933 and parameters: {'n_estimators': 92, 'learning_rate': 0.011552795770417125, 'max_depth': 10}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 00:48:49,498] Trial 2 finished with value: 0.620346379380881 and parameters: {'n_estimators': 220, 'learning_rate': 0.0012705798726321295, 'max_depth': 9}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 00:52:20,529] Trial 3 finished with value: 0.5674348834037911 and parameters: {'n_estimators': 250, 'learning_rate': 0.0023080811708352457, 'max_depth': 4}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 00:54:43,321] Trial 4 finished with value: 0.5342970135006136 and parameters: {'n_estimators': 274, 'learning_rate': 0.0008318184056213453, 'max_depth': 3}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 00:58:04,916] Trial 5 finished with value: 0.6202100095458885 and parameters: {'n_estimators': 54, 'learning_rate': 0.0060092125126385, 'max_depth': 9}. Best is trial 0 with value: 0.7564434747033956.\n",
            "[I 2025-12-24 01:04:18,629] Trial 6 finished with value: 0.7737624437474431 and parameters: {'n_estimators': 196, 'learning_rate': 0.07071337032523153, 'max_depth': 8}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:08:32,888] Trial 7 finished with value: 0.5921178235374335 and parameters: {'n_estimators': 86, 'learning_rate': 0.0012113434844920785, 'max_depth': 8}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:15:45,935] Trial 8 finished with value: 0.6571662348288558 and parameters: {'n_estimators': 250, 'learning_rate': 0.009760275154742308, 'max_depth': 6}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:19:32,934] Trial 9 finished with value: 0.5344333833356062 and parameters: {'n_estimators': 271, 'learning_rate': 0.0003629905915439115, 'max_depth': 4}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:22:58,440] Trial 10 finished with value: 0.7584890222282831 and parameters: {'n_estimators': 164, 'learning_rate': 0.08500691482854025, 'max_depth': 6}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:26:26,962] Trial 11 finished with value: 0.7485340242738306 and parameters: {'n_estimators': 148, 'learning_rate': 0.08022245195619915, 'max_depth': 6}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:31:38,937] Trial 12 finished with value: 0.7222146461202782 and parameters: {'n_estimators': 162, 'learning_rate': 0.04003198393518428, 'max_depth': 7}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:34:19,611] Trial 13 finished with value: 0.6703941088231283 and parameters: {'n_estimators': 138, 'learning_rate': 0.026850076978237564, 'max_depth': 5}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:43:09,612] Trial 14 finished with value: 0.7042138279012682 and parameters: {'n_estimators': 196, 'learning_rate': 0.02072489173952688, 'max_depth': 8}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:49:29,349] Trial 15 finished with value: 0.5866630301377336 and parameters: {'n_estimators': 126, 'learning_rate': 0.00011217487710363668, 'max_depth': 8}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 01:52:19,876] Trial 16 finished with value: 0.7580799127233057 and parameters: {'n_estimators': 189, 'learning_rate': 0.09082425282118035, 'max_depth': 5}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 02:10:04,359] Trial 17 finished with value: 0.7384426564843857 and parameters: {'n_estimators': 299, 'learning_rate': 0.019513875297528734, 'max_depth': 10}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 02:14:11,276] Trial 18 finished with value: 0.7038047183962908 and parameters: {'n_estimators': 117, 'learning_rate': 0.039239355576143796, 'max_depth': 7}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 02:17:54,635] Trial 19 finished with value: 0.596072548752216 and parameters: {'n_estimators': 176, 'learning_rate': 0.004149163985450112, 'max_depth': 5}. Best is trial 6 with value: 0.7737624437474431.\n",
            "[I 2025-12-24 02:25:26,798] Trial 20 finished with value: 0.805400245465703 and parameters: {'n_estimators': 224, 'learning_rate': 0.09748061670866967, 'max_depth': 9}. Best is trial 20 with value: 0.805400245465703.\n",
            "[I 2025-12-24 02:32:58,926] Trial 21 finished with value: 0.808400381835538 and parameters: {'n_estimators': 227, 'learning_rate': 0.09663406952550253, 'max_depth': 9}. Best is trial 21 with value: 0.808400381835538.\n",
            "[I 2025-12-24 02:42:36,678] Trial 22 finished with value: 0.7588981317332606 and parameters: {'n_estimators': 226, 'learning_rate': 0.041556550765612175, 'max_depth': 9}. Best is trial 21 with value: 0.808400381835538.\n",
            "[I 2025-12-24 02:51:43,544] Trial 23 finished with value: 0.7711714168825856 and parameters: {'n_estimators': 231, 'learning_rate': 0.051342506858311904, 'max_depth': 9}. Best is trial 21 with value: 0.808400381835538.\n",
            "[I 2025-12-24 03:01:03,292] Trial 24 finished with value: 0.817673530615028 and parameters: {'n_estimators': 251, 'learning_rate': 0.09952501198524343, 'max_depth': 10}. Best is trial 24 with value: 0.817673530615028.\n",
            "[I 2025-12-24 03:17:50,596] Trial 25 finished with value: 0.7140324560207282 and parameters: {'n_estimators': 250, 'learning_rate': 0.015506883440775688, 'max_depth': 10}. Best is trial 24 with value: 0.817673530615028.\n",
            "[I 2025-12-24 03:33:02,332] Trial 26 finished with value: 0.7628528569480431 and parameters: {'n_estimators': 297, 'learning_rate': 0.030328669170445167, 'max_depth': 10}. Best is trial 24 with value: 0.817673530615028.\n",
            "[I 2025-12-24 03:41:40,891] Trial 27 finished with value: 0.819582708304923 and parameters: {'n_estimators': 276, 'learning_rate': 0.09972400050252742, 'max_depth': 9}. Best is trial 27 with value: 0.819582708304923.\n",
            "[I 2025-12-24 04:02:11,518] Trial 28 finished with value: 0.6733942451929633 and parameters: {'n_estimators': 269, 'learning_rate': 0.006681839365717808, 'max_depth': 10}. Best is trial 27 with value: 0.819582708304923.\n",
            "[I 2025-12-24 04:09:11,672] Trial 29 finished with value: 0.7719896358925405 and parameters: {'n_estimators': 278, 'learning_rate': 0.056242074384928335, 'max_depth': 7}. Best is trial 27 with value: 0.819582708304923.\n"
          ]
        }
      ]
    }
  ]
}